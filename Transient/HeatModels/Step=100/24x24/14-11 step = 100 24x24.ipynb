{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install numba\n",
    "!pip install matplotlib\n",
    "!pip install ray\n",
    "!pip install tqdm\n",
    "!pip install more_itertools\n",
    "!pip install sklearn\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "import more_itertools\n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np\n",
    "from numba import jit ,f8\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sklearn\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver & Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def generate_grid(n,bc,ic=0):\n",
    "    #n=> Number of interior nodes\n",
    "\n",
    "    A = np.ones((n+2,n+2),dtype=np.float32) * ic\n",
    "    A[0,0]=A[-1,-1]=A[0,-1]=A[-1,0]=0\n",
    "    A[0,1:-1]=bc[2]    # switch the top and bottom wall since we start the iterations from top\n",
    "    A[1:-1,-1]=bc[1]\n",
    "    A[-1,1:-1]=bc[0]\n",
    "    A[1:-1,0]=bc[3]\n",
    "\n",
    "    return A\n",
    "\n",
    "@jit(nopython=True)\n",
    "def update_grid_col(grid,x,n):\n",
    "    #first half step update\n",
    "    #x col values ;\n",
    "    #n col number \n",
    "    grid[1:-1,n] = x\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def update_grid_row(grid,x,n):\n",
    "    #second half step update\n",
    "    #x row values ;\n",
    "    #n col number \n",
    "    grid[n,1:-1] = x\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_first_half(A,i,j,lam):\n",
    "    #calculate the ADI explicit part of the equation first half step\n",
    "    if j==1 :\n",
    "        return  lam * A[j][i-1] + 2 *(1-lam) * A[j][i] + lam * A[j][i+1] + lam * A[j-1][i]\n",
    "    elif j== A.shape[0]-2 :\n",
    "        return  lam * A[j][i-1] + 2 *(1-lam) * A[j][i] + lam * A[j][i+1] + lam * A[j+1][i]\n",
    "    else  :\n",
    "        return  lam * A[j][i-1] + 2 *(1-lam) * A[j][i] + lam * A[j][i+1]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_second_half(A,i,j,lam):\n",
    "    #calculate the ADI explicit part of the equation second half step\n",
    "    if i==1 :\n",
    "        return  lam * A[j-1][i] + 2 *(1-lam) * A[j][i] + lam * A[j+1][i] + lam * A[j][i-1]\n",
    "    elif i== A.shape[0]-2 :\n",
    "        return  lam * A[j-1][i] + 2 *(1-lam) * A[j][i] + lam * A[j+1][i] + lam * A[j][i+1]\n",
    "    else  :\n",
    "        return  lam * A[j-1][i] + 2 *(1-lam) * A[j][i] + lam * A[j+1][i]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def generate_TDM(Lambda,N=3):\n",
    "    a = np.ones(N-1,dtype=np.float32)*-Lambda \n",
    "    b =np.ones(N,dtype=np.float32) * 2*(Lambda+1) \n",
    "    return a,b,a\n",
    "\n",
    "@jit(f8[:](f8[:],f8[:],f8[:],f8[:]))\n",
    "def TDMA_solver(a0,b0,c0,d0):\n",
    "    a =np.copy(a0)\n",
    "    b =np.copy(b0)\n",
    "    c =np.copy(c0)\n",
    "    d =np.copy(d0)\n",
    "    ld = len(d)\n",
    "\n",
    "    for i in range(1,ld):\n",
    "        w    = a[i-1]/b[i-1]\n",
    "        b[i] = b[i]- w * c[i-1]\n",
    "        d[i] = d[i] -w * d[i-1]\n",
    "    \n",
    "    R=b\n",
    "    R[-1]=d[-1]/b[-1]\n",
    "    \n",
    "    for i in range(ld-2,-1,-1):\n",
    "        R[i]= (d[i]-c[i]*R[i+1]) /b[i]\n",
    "        \n",
    "    return R\n",
    "\n",
    "@jit(nopython=True)\n",
    "def ADI_first_half_step(grid,Lambda,a,b,c):\n",
    "    #apply ADI for single step\n",
    "\n",
    "    N = grid.shape[0]\n",
    "\n",
    "    ##First half step\n",
    "    for i in range(1,N-1):\n",
    "\n",
    "        # initialize explicit side of equation to zeros\n",
    "        d = np.zeros((N-2))\n",
    "\n",
    "        #move vertically implcitly and calculate horizontally explicitly\n",
    "        for j in range(1,N-1):\n",
    "            d[j-1] =calculate_first_half(grid,i,j,Lambda)\n",
    "\n",
    "        x = TDMA_solver(a,b,c,d)\n",
    "\n",
    "        grid = update_grid_col(grid,x,i)\n",
    "\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def ADI_second_half_step(grid,Lambda,a,b,c):\n",
    "    #apply ADI for single step\n",
    "\n",
    "    N = grid.shape[1]\n",
    "\n",
    "    ##Second half step\n",
    "    for i in range(1,N-1):\n",
    "\n",
    "        # initialize explicit side of equation to zeros\n",
    "        d = np.zeros((N-2))\n",
    "\n",
    "        #move horizontally implcitly and calculate vertically explicitly\n",
    "        for j in range(1,N-1):\n",
    "            d[j-1] =calculate_second_half(grid,j,i,Lambda)\n",
    "\n",
    "        x = TDMA_solver(a,b,c,d)\n",
    "\n",
    "        grid = update_grid_row(grid,x,i)\n",
    "\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def solve(grid,Lambda=1,iters=1,steps=False) :\n",
    "    if steps :\n",
    "        #save intermeidate steps\n",
    "\n",
    "        #(frames,height,width)\n",
    "        grids = np.zeros((iters+1, grid.shape[0],grid.shape[1]),dtype=np.float32)\n",
    "        grids[0,:,:]=grid\n",
    "        a,b,c = generate_TDM(Lambda,grid.shape[0]-2)\n",
    "        #apply ADI iteratively\n",
    "        for i in range(1,iters+1):\n",
    "            grids[i,:,:] = ADI_first_half_step(grid,Lambda,a,b,c)\n",
    "            grids[i,:,:] = ADI_second_half_step(grid,Lambda,a,b,c)\n",
    "\n",
    "\n",
    "    else : \n",
    "        grids = np.zeros((2,grid.shape[0],grid.shape[1]),dtype=np.float32)\n",
    "        #Show final step only\n",
    "        grids[0,:,:]=grid\n",
    "        a,b,c = generate_TDM(Lambda,grid.shape[0]-2)\n",
    "        #apply ADI iteratively\n",
    "        for i in range(iters):\n",
    "            grids[1,:,:] = ADI_first_half_step(grid,Lambda,a,b,c)\n",
    "            grids[1,:,:] = ADI_second_half_step(grid,Lambda,a,b,c)\n",
    "\n",
    "    return grids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pad_grids(grids,Lambda):\n",
    "    grids[:,0,0]=grids[:,-1,0]=grids[:,0,-1]=grids[:,-1,-1]=Lambda * 1000\n",
    "    return grids\n",
    "\n",
    "@ray.remote\n",
    "def solve_permutation(n,iters,permutation):\n",
    "    Lambda,bc1,bc2,bc3,bc4,ic = permutation\n",
    "    grid = generate_grid(n-2,bc=(bc1,bc2,bc3,bc4),ic=ic)\n",
    "    ADIsoltuion = solve(grid.copy(),Lambda = Lambda,iters =iters ,steps=True)\n",
    "    return  np.array(pad_grids(ADIsoltuion,Lambda)).reshape(ADIsoltuion.shape[0],ADIsoltuion.shape[1],ADIsoltuion.shape[2],1)\n",
    "\n",
    "\n",
    "def generate_data(N,iters,permutations):\n",
    "    '''\n",
    "    Input : \n",
    "    N            : size of grid\n",
    "    iters        : max iterations done by solver\n",
    "    permutations : the solution parameters as a set of permutation (Lambda,bc1,..bc4,ic0)\n",
    "    \n",
    "    Output:\n",
    "    solution with shape (iters+1,N,N)\n",
    "    '''\n",
    "    data = [(solve_permutation.remote(N,iters,i)) for i in (permutations) ]\n",
    "    return np.array([ray.get(datalet) for datalet in (data)])\n",
    "    \n",
    "\n",
    "def generate_data_random_permutations(lR=(0,0.25),tR=(0,1000),batches =1,batch_size=32,seed =42,split=1 ):\n",
    "    '''\n",
    "    Input:\n",
    "    *Lambda range\n",
    "    *Temperature range\n",
    "    *Size of data\n",
    "    \n",
    "    Output:\n",
    "    *Generate a generator of size with elements of (Lambda,bc1,..bc4,ic0)\n",
    "    '''\n",
    "    np.random.seed(seed);\n",
    "    lr = np.random.randint(low = tR[0] , high = tR[1] ,size=(batches,batch_size,6)).astype('float')\n",
    "    lr[:,:,0] = ((lR[1]-lR[0])*(lr[:,:,0]-tR[0]))/(tR[1]-tR[0])\n",
    "    return lr\n",
    "\n",
    "\n",
    "def generate_data_batches(N=50,\n",
    "                          lR=(0,0.5),\n",
    "                          tR=(0,100),\n",
    "                          max_iters=10,\n",
    "                          seed=42,\n",
    "                          steps=1,\n",
    "                          step_size=1,\n",
    "                          batch_size=32,\n",
    "                          batches=100,\n",
    "                          progress=True,\n",
    "                          key_bias =0,\n",
    "                          save_file = None):\n",
    "    '''\n",
    "    return dictionary with key of the batch number\n",
    "    '''\n",
    "    if save_file is not None : \n",
    "        hf = h5py.File(save_file,'w')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    perms = generate_data_random_permutations(lR=lR,tR=tR,batch_size=batch_size,batches=batches,seed=seed)\n",
    "    iters_list=  np.random.randint(low=step_size,high=max_iters-step_size*(steps-1)+1,size=batches)\n",
    "\n",
    "    #scaling \n",
    "    mean = (tR[1]-tR[0])/2\n",
    "    std  = mean/2\n",
    "    data={}\n",
    "    \n",
    "    for batch_num in tqdm(range(batches)):\n",
    "        \n",
    "        iter_n = iters_list[batch_num]\n",
    "        \n",
    "        generated_data = generate_data(N,iter_n+steps*step_size,perms[batch_num])\n",
    "        extract_index = np.arange(iter_n-step_size,iter_n+step_size*steps,step_size)\n",
    "#         yield(extract_index)\n",
    "        generated_data = generated_data[:,extract_index,:,:,:]\n",
    "        \n",
    "        if save_file is None :\n",
    "            data[f'{batch_num + key_bias}'] = (generated_data -mean) /std\n",
    "        else : \n",
    "            hf.create_dataset(f'{batch_num}',data = data[batch_num] , compression ='gzip')\n",
    "    \n",
    "    if save_file is not None :hf.close()\n",
    "    else : return data\n",
    "\n",
    "    \n",
    "def data_generator(data):\n",
    "    '''\n",
    "    input : data dictionary (batch number :5D tensor data)\n",
    "    output: input , target values\n",
    "    '''\n",
    "    batches = len(data.keys())\n",
    "    batch_size = len(data['0'])\n",
    "    batch_counter= 0\n",
    "    \n",
    "    while True:\n",
    "        x,y = data[f'{batch_counter}'][:,:-1,:,:,:],data[f'{batch_counter}'][:,-1:,:,:,:]\n",
    "\n",
    "        batch_counter += 1\n",
    "        yield x,y\n",
    "        if batch_counter == batches:batch_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T07:02:16.625562Z",
     "start_time": "2020-10-20T07:01:54.600362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-14 10:04:11,581\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-11-14 10:04:11,591\tWARNING services.py:1560 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 7516192768 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.0.4',\n",
       " 'raylet_ip_address': '172.17.0.4',\n",
       " 'redis_address': '172.17.0.4:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-11-14_10-04-10_960750_21336/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-11-14_10-04-10_960750_21336/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-11-14_10-04-10_960750_21336',\n",
       " 'metrics_export_port': 65317,\n",
       " 'node_id': 'fb236d48c7f2416f3940153d301caed3d981d63c'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-20T07:04:32.404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e3afcb2d674789b6d56127edbf7209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_batches =generate_data_batches(N=24,\n",
    "                                          lR=(0,1),\n",
    "                                          tR=(0,1_000),\n",
    "                                          max_iters=1000,\n",
    "                                          seed=42,\n",
    "                                          batch_size=32,\n",
    "                                          step_size= 100,\n",
    "                                          steps=1,\n",
    "                                          batches=9000,\n",
    "                                          progress=True)\n",
    "#                                           save_file = 'N=100x100 batch_size=64 batches=5000 max_iters=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-20T07:04:32.404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dca305f9a74945906d9350234d2d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_batches_bias =generate_data_batches(N=24,\n",
    "                                          lR=(0,1),\n",
    "                                          tR=(0,1_000),\n",
    "                                          max_iters=120,\n",
    "                                          seed=42,\n",
    "                                          batch_size=32,\n",
    "                                          step_size= 100,\n",
    "                                          steps=1,\n",
    "                                          batches =1_000,\n",
    "                                          key_bias = 9_000,\n",
    "                                          progress = True)\n",
    "#                                           save_file = 'N=100x100 batch_size=64 batches=5000 max_iters=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T06:28:14.703199Z",
     "start_time": "2020-10-15T06:28:10.596157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028d279a4d8c41208c5db5ecfb595fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validation_data_batches =generate_data_batches(N=24,\n",
    "                                              lR=(0,1),\n",
    "                                              tR=(0,1_000),\n",
    "                                              max_iters=1000,\n",
    "                                              seed=0,\n",
    "                                              batch_size=32,\n",
    "                                              step_size= 100,\n",
    "                                              steps=1,\n",
    "                                              batches=50,\n",
    "                                              progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv(x,f,k):\n",
    "    x = TimeDistributed(Conv2D(f,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return x\n",
    "    \n",
    "def deconv(x,f,k):\n",
    "    x = TimeDistributed(Conv2DTranspose(f,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "def dense_block(tensor, f, r,k):\n",
    "    for _ in range(r):\n",
    "        x = conv(tensor, f=4*f, k=1)\n",
    "        x = conv(x, f=f, k=k)\n",
    "        tensor = Concatenate()([tensor, x])\n",
    "    return tensor\n",
    "\n",
    "def inv_dense_block(tensor, f, r,k):\n",
    "    for _ in range(r):\n",
    "        x = deconv(tensor, f=4*f, k=1)\n",
    "        x = deconv(x, f=f, k=k)\n",
    "        tensor = Concatenate()([tensor, x])\n",
    "    return tensor\n",
    "\n",
    "def transition(x,s):\n",
    "    ff = int(tensorflow.keras.backend.int_shape(x)[-1] * 0.5)\n",
    "    m0 = TimeDistributed(Conv2D(ff,(1,1),strides=2*s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return m0\n",
    "\n",
    "def inv_transition(x,s):\n",
    "    ff = int(tensorflow.keras.backend.int_shape(x)[-1] * 0.5)\n",
    "    m0 = TimeDistributed(Conv2DTranspose(ff,(1,1),strides=2*s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return m0\n",
    "\n",
    "\n",
    "def dfn():\n",
    "    \n",
    "    k=3\n",
    "    s=1;\n",
    "    LR=1e-4\n",
    "    \n",
    "    r1,r2,r3 = 2 , 4 ,8\n",
    "    f0,f1,f2,f3 = 128,32,32,32\n",
    "    l1,l2 = 128 ,64\n",
    "\n",
    "    x = Input(shape=(None, None,None, 1))\n",
    "    c0 = TimeDistributed(Conv2D(f0,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "########################################################################################################    \n",
    "    e1 = dense_block(c0,f1,r=r1,k=k);m1 = transition(e1,s)\n",
    "    e2 = dense_block(m1,f2,r=r2,k=k);m2 = transition(e2,s)\n",
    "    e3 = dense_block(m2,f3,r=r3,k=k);\n",
    "########################################################################################################\n",
    "    e = ConvLSTM2D(l1,(2,2),padding='same',return_sequences=True)(e3)\n",
    "    b = ConvLSTM2D(l2,(2,2),padding='same',return_sequences=True)(e)\n",
    "    d = ConvLSTM2D(l1,(2,2),padding='same',return_sequences=True)(b)\n",
    "########################################################################################################\n",
    "    d1 = inv_dense_block(d ,f3,r=r3,k=k);m1 = inv_transition(d1,s)\n",
    "    d2 = inv_dense_block(m1,f2,r=r2,k=k);m2 = inv_transition(d2,s)\n",
    "    d3 = inv_dense_block(m2,f1,r=r1,k=k);\n",
    "########################################################################################################\n",
    "    out = conv(d3,f=1,k=1)\n",
    "    model = Model(x,out)\n",
    "    optimizer = Adam(learning_rate=LR)\n",
    "    model.compile(loss='mae',optimizer=optimizer,metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "model = dfn()\n",
    "# model.summary()\n",
    "# keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T06:48:10.103493Z",
     "start_time": "2020-10-15T06:48:10.090529Z"
    }
   },
   "outputs": [],
   "source": [
    "history={}\n",
    "i = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 800s 78ms/step - loss: 0.1093 - mse: 0.0720 - val_loss: 0.0628 - val_mse: 0.0330\n",
      "\n",
      "Epoch 00001: saving model to step=100 24x24.h5\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 782s 78ms/step - loss: 0.0406 - mse: 0.0204 - val_loss: 0.0572 - val_mse: 0.0305\n",
      "\n",
      "Epoch 00002: saving model to step=100 24x24.h5\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 783s 78ms/step - loss: 0.0341 - mse: 0.0172 - val_loss: 0.0206 - val_mse: 0.0101\n",
      "\n",
      "Epoch 00003: saving model to step=100 24x24.h5\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 782s 78ms/step - loss: 0.0184 - mse: 0.0101 - val_loss: 0.0196 - val_mse: 0.0094\n",
      "\n",
      "Epoch 00004: saving model to step=100 24x24.h5\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 785s 78ms/step - loss: 0.0165 - mse: 0.0089 - val_loss: 0.0181 - val_mse: 0.0073\n",
      "\n",
      "Epoch 00005: saving model to step=100 24x24.h5\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 787s 79ms/step - loss: 0.0142 - mse: 0.0073 - val_loss: 0.0141 - val_mse: 0.0071\n",
      "\n",
      "Epoch 00006: saving model to step=100 24x24.h5\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 789s 79ms/step - loss: 0.0133 - mse: 0.0072 - val_loss: 0.0143 - val_mse: 0.0070\n",
      "\n",
      "Epoch 00007: saving model to step=100 24x24.h5\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 786s 79ms/step - loss: 0.0129 - mse: 0.0071 - val_loss: 0.0128 - val_mse: 0.0068\n",
      "\n",
      "Epoch 00008: saving model to step=100 24x24.h5\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 787s 79ms/step - loss: 0.0124 - mse: 0.0069 - val_loss: 0.0124 - val_mse: 0.0061\n",
      "\n",
      "Epoch 00009: saving model to step=100 24x24.h5\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 786s 79ms/step - loss: 0.0106 - mse: 0.0043 - val_loss: 0.0091 - val_mse: 0.0025\n",
      "\n",
      "Epoch 00010: saving model to step=100 24x24.h5\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 789s 79ms/step - loss: 0.0087 - mse: 0.0025 - val_loss: 0.0105 - val_mse: 0.0023\n",
      "\n",
      "Epoch 00011: saving model to step=100 24x24.h5\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 781s 78ms/step - loss: 0.0081 - mse: 0.0019 - val_loss: 0.0065 - val_mse: 2.5880e-04\n",
      "\n",
      "Epoch 00012: saving model to step=100 24x24.h5\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 779s 78ms/step - loss: 0.0065 - mse: 1.7462e-04 - val_loss: 0.0054 - val_mse: 1.4972e-04\n",
      "\n",
      "Epoch 00013: saving model to step=100 24x24.h5\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 782s 78ms/step - loss: 0.0062 - mse: 1.5313e-04 - val_loss: 0.0100 - val_mse: 2.9860e-04\n",
      "\n",
      "Epoch 00014: saving model to step=100 24x24.h5\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 780s 78ms/step - loss: 0.0060 - mse: 1.4654e-04 - val_loss: 0.0080 - val_mse: 1.7586e-04\n",
      "\n",
      "Epoch 00015: saving model to step=100 24x24.h5\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 783s 78ms/step - loss: 0.0058 - mse: 1.3527e-04 - val_loss: 0.0078 - val_mse: 1.9440e-04\n",
      "\n",
      "Epoch 00016: saving model to step=100 24x24.h5\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 786s 79ms/step - loss: 0.0057 - mse: 1.3021e-04 - val_loss: 0.0063 - val_mse: 1.5029e-04\n",
      "\n",
      "Epoch 00017: saving model to step=100 24x24.h5\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 776s 78ms/step - loss: 0.0054 - mse: 1.1536e-04 - val_loss: 0.0047 - val_mse: 1.2650e-04\n",
      "\n",
      "Epoch 00018: saving model to step=100 24x24.h5\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 777s 78ms/step - loss: 0.0053 - mse: 1.0910e-04 - val_loss: 0.0061 - val_mse: 1.2404e-04\n",
      "\n",
      "Epoch 00019: saving model to step=100 24x24.h5\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 781s 78ms/step - loss: 0.0053 - mse: 1.0313e-04 - val_loss: 0.0057 - val_mse: 1.0793e-04\n",
      "\n",
      "Epoch 00020: saving model to step=100 24x24.h5\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 782s 78ms/step - loss: 0.0052 - mse: 9.9877e-05 - val_loss: 0.0043 - val_mse: 1.0449e-04\n",
      "\n",
      "Epoch 00021: saving model to step=100 24x24.h5\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 786s 79ms/step - loss: 0.0050 - mse: 9.5818e-05 - val_loss: 0.0041 - val_mse: 1.1589e-04\n",
      "\n",
      "Epoch 00022: saving model to step=100 24x24.h5\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 779s 78ms/step - loss: 0.0049 - mse: 8.8083e-05 - val_loss: 0.0071 - val_mse: 1.1625e-04\n",
      "\n",
      "Epoch 00023: saving model to step=100 24x24.h5\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 780s 78ms/step - loss: 0.0048 - mse: 8.7640e-05 - val_loss: 0.0040 - val_mse: 6.9258e-05\n",
      "\n",
      "Epoch 00024: saving model to step=100 24x24.h5\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 777s 78ms/step - loss: 0.0048 - mse: 8.2158e-05 - val_loss: 0.0063 - val_mse: 1.1069e-04\n",
      "\n",
      "Epoch 00025: saving model to step=100 24x24.h5\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 779s 78ms/step - loss: 0.0048 - mse: 8.4591e-05 - val_loss: 0.0044 - val_mse: 9.7737e-05\n",
      "\n",
      "Epoch 00026: saving model to step=100 24x24.h5\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 786s 79ms/step - loss: 0.0046 - mse: 7.9145e-05 - val_loss: 0.0048 - val_mse: 7.7919e-05\n",
      "\n",
      "Epoch 00027: saving model to step=100 24x24.h5\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 779s 78ms/step - loss: 0.0046 - mse: 7.5964e-05 - val_loss: 0.0061 - val_mse: 1.0198e-04\n",
      "\n",
      "Epoch 00028: saving model to step=100 24x24.h5\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 782s 78ms/step - loss: 0.0045 - mse: 7.4086e-05 - val_loss: 0.0050 - val_mse: 9.3036e-05\n",
      "\n",
      "Epoch 00029: saving model to step=100 24x24.h5\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 781s 78ms/step - loss: 0.0045 - mse: 7.7677e-05 - val_loss: 0.0043 - val_mse: 1.1004e-04\n",
      "\n",
      "Epoch 00030: saving model to step=100 24x24.h5\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 779s 78ms/step - loss: 0.0043 - mse: 7.0862e-05 - val_loss: 0.0048 - val_mse: 1.0710e-04\n",
      "\n",
      "Epoch 00031: saving model to step=100 24x24.h5\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 782s 78ms/step - loss: 0.0043 - mse: 6.5936e-05 - val_loss: 0.0076 - val_mse: 1.6143e-04\n",
      "\n",
      "Epoch 00032: saving model to step=100 24x24.h5\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 787s 79ms/step - loss: 0.0043 - mse: 6.8105e-05 - val_loss: 0.0041 - val_mse: 7.2860e-05\n",
      "\n",
      "Epoch 00033: saving model to step=100 24x24.h5\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 792s 79ms/step - loss: 0.0043 - mse: 6.5460e-05 - val_loss: 0.0051 - val_mse: 8.1974e-05\n",
      "\n",
      "Epoch 00034: saving model to step=100 24x24.h5\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 787s 79ms/step - loss: 0.0041 - mse: 5.9941e-05 - val_loss: 0.0060 - val_mse: 7.0372e-05\n",
      "\n",
      "Epoch 00035: saving model to step=100 24x24.h5\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 789s 79ms/step - loss: 0.0041 - mse: 5.9937e-05 - val_loss: 0.0039 - val_mse: 5.9181e-05\n",
      "\n",
      "Epoch 00036: saving model to step=100 24x24.h5\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 785s 79ms/step - loss: 0.0040 - mse: 5.8625e-05 - val_loss: 0.0045 - val_mse: 5.0785e-05\n",
      "\n",
      "Epoch 00037: saving model to step=100 24x24.h5\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 782s 78ms/step - loss: 0.0041 - mse: 6.0356e-05 - val_loss: 0.0051 - val_mse: 7.5792e-05\n",
      "\n",
      "Epoch 00038: saving model to step=100 24x24.h5\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 771s 77ms/step - loss: 0.0041 - mse: 5.7570e-05 - val_loss: 0.0053 - val_mse: 7.0475e-05\n",
      "\n",
      "Epoch 00039: saving model to step=100 24x24.h5\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 758s 76ms/step - loss: 0.0039 - mse: 5.4936e-05 - val_loss: 0.0034 - val_mse: 4.3566e-05\n",
      "\n",
      "Epoch 00040: saving model to step=100 24x24.h5\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 760s 76ms/step - loss: 0.0038 - mse: 5.3245e-05 - val_loss: 0.0039 - val_mse: 5.1751e-05\n",
      "\n",
      "Epoch 00041: saving model to step=100 24x24.h5\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 757s 76ms/step - loss: 0.0039 - mse: 5.4188e-05 - val_loss: 0.0038 - val_mse: 5.6468e-05\n",
      "\n",
      "Epoch 00042: saving model to step=100 24x24.h5\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 762s 76ms/step - loss: 0.0039 - mse: 5.3745e-05 - val_loss: 0.0050 - val_mse: 5.8642e-05\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00043: saving model to step=100 24x24.h5\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 764s 76ms/step - loss: 0.0021 - mse: 1.8898e-05 - val_loss: 0.0023 - val_mse: 3.2518e-05\n",
      "\n",
      "Epoch 00044: saving model to step=100 24x24.h5\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 771s 77ms/step - loss: 0.0021 - mse: 1.8269e-05 - val_loss: 0.0017 - val_mse: 1.8853e-05\n",
      "\n",
      "Epoch 00045: saving model to step=100 24x24.h5\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 780s 78ms/step - loss: 0.0021 - mse: 1.8133e-05 - val_loss: 0.0024 - val_mse: 2.2497e-05\n",
      "\n",
      "Epoch 00046: saving model to step=100 24x24.h5\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 778s 78ms/step - loss: 0.0020 - mse: 1.5981e-05 - val_loss: 0.0020 - val_mse: 2.6303e-05\n",
      "\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00047: saving model to step=100 24x24.h5\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 765s 77ms/step - loss: 0.0013 - mse: 8.6780e-06 - val_loss: 0.0017 - val_mse: 2.2595e-05\n",
      "\n",
      "Epoch 00048: saving model to step=100 24x24.h5\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 767s 77ms/step - loss: 0.0013 - mse: 8.0554e-06 - val_loss: 0.0017 - val_mse: 1.8768e-05\n",
      "\n",
      "Epoch 00049: saving model to step=100 24x24.h5\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 767s 77ms/step - loss: 0.0013 - mse: 7.7953e-06 - val_loss: 0.0015 - val_mse: 1.8600e-05\n",
      "\n",
      "Epoch 00050: saving model to step=100 24x24.h5\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 770s 77ms/step - loss: 0.0012 - mse: 8.0399e-06 - val_loss: 0.0017 - val_mse: 2.0173e-05\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00051: saving model to step=100 24x24.h5\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 768s 77ms/step - loss: 9.1039e-04 - mse: 5.1105e-06 - val_loss: 0.0011 - val_mse: 1.5936e-05\n",
      "\n",
      "Epoch 00052: saving model to step=100 24x24.h5\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 773s 77ms/step - loss: 9.0245e-04 - mse: 4.7388e-06 - val_loss: 0.0011 - val_mse: 1.4967e-05\n",
      "\n",
      "Epoch 00053: saving model to step=100 24x24.h5\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 767s 77ms/step - loss: 8.8664e-04 - mse: 4.5567e-06 - val_loss: 0.0011 - val_mse: 1.4314e-05\n",
      "\n",
      "Epoch 00054: saving model to step=100 24x24.h5\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 770s 77ms/step - loss: 8.8274e-04 - mse: 4.4927e-06 - val_loss: 0.0011 - val_mse: 1.4471e-05\n",
      "\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00055: saving model to step=100 24x24.h5\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 769s 77ms/step - loss: 7.6331e-04 - mse: 3.8386e-06 - val_loss: 9.7731e-04 - val_mse: 1.0755e-05\n",
      "\n",
      "Epoch 00056: saving model to step=100 24x24.h5\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 771s 77ms/step - loss: 7.5377e-04 - mse: 3.5800e-06 - val_loss: 9.6116e-04 - val_mse: 1.0682e-05\n",
      "\n",
      "Epoch 00057: saving model to step=100 24x24.h5\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 772s 77ms/step - loss: 7.4639e-04 - mse: 3.5050e-06 - val_loss: 9.4979e-04 - val_mse: 1.0630e-05\n",
      "\n",
      "Epoch 00058: saving model to step=100 24x24.h5\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 772s 77ms/step - loss: 7.4198e-04 - mse: 3.4442e-06 - val_loss: 9.3594e-04 - val_mse: 1.0394e-05\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00059: saving model to step=100 24x24.h5\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 774s 77ms/step - loss: 6.9203e-04 - mse: 3.2040e-06 - val_loss: 8.1353e-04 - val_mse: 8.4546e-06\n",
      "\n",
      "Epoch 00060: saving model to step=100 24x24.h5\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 769s 77ms/step - loss: 6.8638e-04 - mse: 3.0753e-06 - val_loss: 8.0599e-04 - val_mse: 8.3540e-06\n",
      "\n",
      "Epoch 00061: saving model to step=100 24x24.h5\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 769s 77ms/step - loss: 6.8218e-04 - mse: 3.0359e-06 - val_loss: 7.9952e-04 - val_mse: 8.2905e-06\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00062: saving model to step=100 24x24.h5\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 769s 77ms/step - loss: 6.6230e-04 - mse: 2.9510e-06 - val_loss: 7.7079e-04 - val_mse: 8.0004e-06\n",
      "\n",
      "Epoch 00063: saving model to step=100 24x24.h5\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 773s 77ms/step - loss: 6.5748e-04 - mse: 2.8678e-06 - val_loss: 7.6786e-04 - val_mse: 7.9436e-06\n",
      "\n",
      "Epoch 00064: saving model to step=100 24x24.h5\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 774s 77ms/step - loss: 6.5519e-04 - mse: 2.8415e-06 - val_loss: 7.6482e-04 - val_mse: 7.8733e-06\n",
      "\n",
      "Epoch 00065: saving model to step=100 24x24.h5\n",
      "Epoch 00065: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f17587575c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_logger = tensorflow.keras.callbacks.CSVLogger('train step=100 24x24.log')\n",
    "early_stopping = tensorflow.keras.callbacks.EarlyStopping(monitor='loss',min_delta=5e-5, patience=5, verbose=1, mode='auto',baseline=None, restore_best_weights=False)\n",
    "reduce_lr_callback = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',factor = 0.5,patience = 3,verbose = 1,cooldown=1,min_delta = 1e-4,min_lr=1e-8 )\n",
    "model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint('step=100 24x24.h5', monitor='loss', verbose=1, save_best_only=False,save_weights_only=False, mode='auto', save_freq='epoch',)\n",
    "model.fit(data_generator({**train_data_batches,**train_data_batches_bias}),\n",
    "          validation_data=data_generator(validation_data_batches),\n",
    "          steps_per_epoch=len({**train_data_batches,**train_data_batches_bias}),\n",
    "          validation_steps=len(validation_data_batches),\n",
    "          verbose=1,\n",
    "          epochs=100,\n",
    "          callbacks=[reduce_lr_callback,early_stopping,csv_logger,model_checkpoint_callback],\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('step=100 24x24 loss=63519e-4 7.6482e-4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:59:56.465051Z",
     "start_time": "2020-10-17T14:59:55.611505Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:59:57.984142Z",
     "start_time": "2020-10-17T14:59:57.671939Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "def show_heat_maps(*grids,annotate=False,save=None , rc=None,figsize=(30,10),cbar_location='left'):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if rc is  None : rc=(1,len(grids))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=rc,axes_pad=0.25,share_all=True,cbar_location=cbar_location,cbar_mode=\"single\",cbar_size=\"5%\",cbar_pad=0.25,)\n",
    "    for ax,g in zip(grid,grids):\n",
    "        im = ax.imshow(g[0]) ; \n",
    "        ax.title.set_text(g[1])\n",
    "        if annotate:\n",
    "            N,M = int(g[0].shape[0]),int(g[0].shape[1])\n",
    "            for k in range(N):\n",
    "                for j in range(M):\n",
    "                    text1 = ax.text(j, k, np.round(g[0][k, j],1),ha=\"center\", va=\"center\", color=\"w\",fontsize=20)\n",
    "\n",
    "\n",
    "        ax.cax.colorbar(im)\n",
    "        ax.cax.toggle_label(True)\n",
    "    \n",
    "    if save is not None : plt.savefig(save)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T15:03:22.983589Z",
     "start_time": "2020-10-17T15:03:17.236703Z"
    }
   },
   "outputs": [],
   "source": [
    "import  tensorflow\n",
    "loaded_model = model #tensorflow.keras.models.load_model('48x48 loss=6.152e-4 7.5453e-4.h5')\n",
    "loaded_model2 = model # model_scaled #tensorflow.keras.models.load_model('bias 100x100 step=10 loss=0.0012 model 27th october model.h5')\n",
    "\n",
    "# loaded_model2 = keras.models.load_model('100x100 step=10 loss=0.008 model 17th october model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "layout = ipywidgets.Layout(width= '100%',height='20px')\n",
    "\n",
    "bc1 = ipywidgets.IntSlider(min=0,max=1000,value = 600,step=1,description='bc1 # ' ,layout=layout,continuous_update=False)\n",
    "bc2 = ipywidgets.IntSlider(min=0,max=1000,value=500,step=1,description='bc2 # ' ,layout=layout,continuous_update=False)\n",
    "bc3 = ipywidgets.IntSlider(min=0,max=1000,value=100,step=1,description='bc3 # ' ,layout=layout,continuous_update=False)\n",
    "bc4 = ipywidgets.IntSlider(min=0,max=1000,step=1,value=400,description='bc4 # ' ,layout=layout,continuous_update=False)\n",
    "ic0 = ipywidgets.IntSlider(min=0,max=1000,step=1,value=100,description='ic # ' ,layout=layout,continuous_update=False)\n",
    "lam = ipywidgets.FloatSlider(min=0,max=0.5,value=0.125,step=0.00001,description='lambda # ' ,layout=layout,continuous_update=False,readout_format='.5f')\n",
    "\n",
    "\n",
    "t00 = ipywidgets.IntSlider(min=0,max=10_000,step=1,value=0,description='t00 # ' ,layout=layout,continuous_update=False)\n",
    "t0f = ipywidgets.IntSlider(min=0,max=50_000,step=1,value=t00.value+100,description='t0f # ' ,layout=layout,continuous_update=False)\n",
    "\n",
    "@ipywidgets.interact(bc1=bc1,bc2=bc2,bc3=bc3,bc4=bc4,ic0=ic0,lam=lam,t00=t00,t0f=t0f,analyze=False,plot=False,save=False)\n",
    "def compare_solution(bc1,bc2,bc3,bc4,ic0,lam,t00,t0f,analyze=False,plot=False,save=False):\n",
    "    size = 12  ; mean = 5_00  ;  std  = 2_50 ; step = 10  ; total_step = 1\n",
    "   \n",
    "    '''\n",
    "    generate the adi solution in shape of \n",
    "    (frames , rows ,cols)\n",
    "    '''\n",
    "    tic = time.time()\n",
    "    \n",
    "    grid = generate_grid( size - 2 , bc =(bc1,bc2,bc3,bc4),ic=ic0)\n",
    "    adi_solution = solve(grid.copy(), iters = t00+step*total_step ,Lambda= lam ,steps=True)\n",
    "    toc = time.time()\n",
    "    \n",
    "    print(f'Numerical solution excuted in {(toc-tic)*1e3}ms')\n",
    "    \n",
    "    '''\n",
    "    model expects scaled input 5d tensor in shape of \n",
    "    ( sample size , frames number , rows , cols , channels )\n",
    "    standard scaling using mean = 500  ,std = 250\n",
    "    '''\n",
    "    if analyze :\n",
    "        # Preprocessing\n",
    "        model_input = pad_grids(adi_solution,lam)   #pad\n",
    "        model_input = ( adi_solution[t00:t00+1,:,:] - mean ) / std  #scale \n",
    "        model_input = model_input.reshape(1,1,size,size,1)        #reshape to 5d tensor\n",
    "\n",
    "        \n",
    "        plot_list =[]\n",
    "        \n",
    "        prediction_solutions = {}\n",
    "        \n",
    "        tic = time.time() ; \n",
    "        \n",
    "        prediction_solutions[0] = model_input ; \n",
    "        \n",
    "        for i in range(0,total_step+1):\n",
    "            prediction_solutions[i+1] = loaded_model.predict(prediction_solutions[i])\n",
    "        \n",
    "        for i in range(0,total_step+1):\n",
    "            correct    = (adi_solution[t00+step*(i)],f'$Step={t00+step*(i)}$')\n",
    "            prediction = ((prediction_solutions[i][0,0,:,:,0]*std )+mean , f'$Step={t00+step*(i)}$')\n",
    "            plot_list.append(correct)\n",
    "            plot_list.append(prediction)\n",
    "            print(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if plot :\n",
    "            if save :path = f'bc:{bc1},{bc2},{bc3},{bc4},{ic0}-lam:{lam}-t00:{t00}.svg' \n",
    "            else: path = None\n",
    "            print('MAE error:',sklearn.metrics.mean_absolute_error(adi_solution[t00+step*(0+1),1:-1,1:-1],prediction_solutions[0][0,0,1:-1,1:-1,0]))\n",
    "            \n",
    "            show_heat_maps(\n",
    "                *plot_list,\n",
    "                annotate=True,\n",
    "                figsize=(50,50),\n",
    "                rc=(len(plot_list)//2,2),\n",
    "                cbar_location='bottom'\n",
    "#             save=path           \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =[1,'']\n",
    "b = [2,'']\n",
    "\n",
    "tuple(b),tuple(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.load_model('12 24 48 96 loss=0.0013.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-20T07:04:32.404Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_batches =generate_data_batches(N=12,\n",
    "                                          lR=(0,1),\n",
    "                                          tR=(0,1_000),\n",
    "                                          max_iters=1000,\n",
    "                                          seed=192,\n",
    "                                          batch_size=1,\n",
    "                                          step_size= 100,\n",
    "                                          steps=1,\n",
    "                                          batches=1000,\n",
    "                                          progress=True)\n",
    "#                                           save_file = 'N=100x100 batch_size=64 batches=5000 max_iters=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(data_generator(test_data_batches),steps=len(test_data_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros(1000);std= np.zeros(1000)\n",
    "for bi in test_data_batches:\n",
    "    mean[int(bi)] = np.mean((test_data_batches_12x12[bi] *250 )+ 500) \n",
    "    std[int(bi)]= np.std((test_data_batches_12x12[bi]*250)+500)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(mean)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
