{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numba\n",
      "  Downloading numba-0.51.2-cp36-cp36m-manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 5.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from numba) (1.19.4)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba) (50.3.2)\n",
      "Collecting llvmlite<0.35,>=0.34.0.dev0\n",
      "  Downloading llvmlite-0.34.0-cp36-cp36m-manylinux2010_x86_64.whl (24.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.6 MB 22.1 MB/s eta 0:00:01    |█████▌                          | 4.2 MB 22.1 MB/s eta 0:00:01     |██████████████████████████████▎ | 23.3 MB 22.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: llvmlite, numba\n",
      "Successfully installed llvmlite-0.34.0 numba-0.51.2\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.2-cp36-cp36m-manylinux1_x86_64.whl (11.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.6 MB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 45.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 42.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.19.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2020.11.8)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Installing collected packages: kiwisolver, pillow, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.2 pillow-8.0.1\n",
      "Collecting ray\n",
      "  Downloading ray-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (23.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.1 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray) (3.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ray) (2.24.0)\n",
      "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray) (3.13.0)\n",
      "Collecting google\n",
      "  Downloading google-3.0.0-py2.py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 6.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.7.2-cp36-cp36m-manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 34.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gpustat\n",
      "  Downloading gpustat-0.6.0.tar.gz (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 10.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "\u001b[K     |████████████████████████████████| 269 kB 29.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencensus\n",
      "  Downloading opencensus-0.7.11-py2.py3-none-any.whl (127 kB)\n",
      "\u001b[K     |████████████████████████████████| 127 kB 42.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray) (0.8.0)\n",
      "Collecting aioredis\n",
      "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 7.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting py-spy>=0.2.0\n",
      "  Downloading py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 49.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click>=7.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 2.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting msgpack<2.0.0,>=1.0.0\n",
      "  Downloading msgpack-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (274 kB)\n",
      "\u001b[K     |████████████████████████████████| 274 kB 36.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting colorful\n",
      "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
      "\u001b[K     |████████████████████████████████| 201 kB 37.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp-cors\n",
      "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting redis<3.5.0,>=3.3.2\n",
      "  Downloading redis-3.4.1-py2.py3-none-any.whl (71 kB)\n",
      "\u001b[K     |████████████████████████████████| 71 kB 14.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from ray) (1.19.4)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema->ray) (20.3.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from jsonschema->ray) (50.3.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema->ray) (2.0.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema->ray) (0.17.3)\n",
      "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema->ray) (1.15.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->ray) (2.6)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ray) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray) (2020.11.8)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "\u001b[K     |████████████████████████████████| 115 kB 38.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.2-cp36-cp36m-manylinux2014_x86_64.whl (295 kB)\n",
      "\u001b[K     |████████████████████████████████| 295 kB 44.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray) (3.7.4.3)\n",
      "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
      "  Downloading idna-ssl-1.1.0.tar.gz (3.4 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.0.0-cp36-cp36m-manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[K     |████████████████████████████████| 141 kB 50.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Collecting psutil\n",
      "  Downloading psutil-5.7.3.tar.gz (465 kB)\n",
      "\u001b[K     |████████████████████████████████| 465 kB 40.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blessings>=1.6\n",
      "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Collecting google-api-core<2.0.0,>=1.0.0\n",
      "  Downloading google_api_core-1.23.0-py2.py3-none-any.whl (91 kB)\n",
      "\u001b[K     |████████████████████████████████| 91 kB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting opencensus-context==0.1.2\n",
      "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting hiredis\n",
      "  Downloading hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 13.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema->ray) (3.4.0)\n",
      "Collecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.0.1-py3-none-any.whl (32 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2020.4-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 33.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.52.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 16.0 MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.23.0)\n",
      "Collecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n",
      "  Downloading contextvars-2.4.tar.gz (9.6 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.1.1)\n",
      "Collecting immutables>=0.9\n",
      "  Downloading immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 12.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n",
      "Building wheels for collected packages: gpustat, pyyaml, idna-ssl, nvidia-ml-py3, psutil, contextvars\n",
      "  Building wheel for gpustat (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gpustat: filename=gpustat-0.6.0-py3-none-any.whl size=12617 sha256=f4fc35a22f0ec364d29c93f0033bd5cf443790e5a798098f5d33dcc364160d22\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/da/35/fe2cfb3bc47822299f5e124a599d56f00b30ec0b328db16b9f\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyyaml: filename=PyYAML-5.3.1-cp36-cp36m-linux_x86_64.whl size=44619 sha256=c5b850c988e783946909c9bc7462cd56febe647a092eac273326e5be8496cf42\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/9d/ad/2ee53cf262cba1ffd8afe1487eef788ea3f260b7e6232a80fc\n",
      "  Building wheel for idna-ssl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-py3-none-any.whl size=3161 sha256=34b228e8fbd993f45528cd7774d7e5730806aa5a0e9b8bae5692e301bdc8a9bf\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/f5/9c/f8331a854f7a8739cf0e74c13854e4dd7b1af11b04fe1dde13\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19191 sha256=2413c4f5b61fe63c9ffd5822c258bb9dc006aa5e30f8ceb0693a77e376b51246\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/26/a3/33f2079871e2bebb3f53a2b21c3ec64129b8efdd18a6263a52\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.3-cp36-cp36m-linux_x86_64.whl size=281530 sha256=70c75d5257db6235d42a7879f0d73b9d61dfac19f8f9be716ea2292cc5e5edac\n",
      "  Stored in directory: /root/.cache/pip/wheels/fa/ad/67/90bbaacdcfe970960dd5158397f23a6579b51d853720d7856d\n",
      "  Building wheel for contextvars (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for contextvars: filename=contextvars-2.4-py3-none-any.whl size=7665 sha256=17960c72c8e9cd625d0500b205e227a318a2edab1ad255603caf8cbdc831153a\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/11/53/911724983aa48deb94792432e14e518447212dd6c5477d49d3\n",
      "Successfully built gpustat pyyaml idna-ssl nvidia-ml-py3 psutil contextvars\n",
      "Installing collected packages: filelock, soupsieve, beautifulsoup4, google, multidict, yarl, idna-ssl, async-timeout, aiohttp, nvidia-ml-py3, psutil, blessings, gpustat, pyyaml, pytz, googleapis-common-protos, google-api-core, immutables, contextvars, opencensus-context, opencensus, hiredis, aioredis, py-spy, click, msgpack, colorful, aiohttp-cors, colorama, redis, ray\n",
      "Successfully installed aiohttp-3.7.2 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 beautifulsoup4-4.9.3 blessings-1.7 click-7.1.2 colorama-0.4.4 colorful-0.5.4 contextvars-2.4 filelock-3.0.12 google-3.0.0 google-api-core-1.23.0 googleapis-common-protos-1.52.0 gpustat-0.6.0 hiredis-1.1.0 idna-ssl-1.1.0 immutables-0.14 msgpack-1.0.0 multidict-5.0.0 nvidia-ml-py3-7.352.0 opencensus-0.7.11 opencensus-context-0.1.2 psutil-5.7.3 py-spy-0.3.3 pytz-2020.4 pyyaml-5.3.1 ray-1.0.1 redis-3.4.1 soupsieve-2.0.1 yarl-1.6.2\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 4.3 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.51.0\n",
      "Collecting more_itertools\n",
      "  Downloading more_itertools-8.6.0-py3-none-any.whl (45 kB)\n",
      "\u001b[K     |████████████████████████████████| 45 kB 3.3 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: more-itertools\n",
      "Successfully installed more-itertools-8.6.0\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.8 MB 2.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 15.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.19.4)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 48.1 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=45c206c5bce1953bcefcfef2f57c6c6ea9c2d0b5388234437b304be579a79ba4\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.17.0 scikit-learn-0.23.2 scipy-1.5.4 sklearn-0.0 threadpoolctl-2.1.0\n",
      "Collecting pydot\n",
      "  Downloading pydot-1.4.1-py2.py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from pydot) (2.4.7)\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.4.1\n"
     ]
    }
   ],
   "source": [
    "!pip install numba\n",
    "!pip install matplotlib\n",
    "!pip install ray\n",
    "!pip install tqdm\n",
    "!pip install more_itertools\n",
    "!pip install sklearn\n",
    "!pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ray\n",
    "import more_itertools\n",
    "from tqdm.notebook import tqdm \n",
    "import numpy as np\n",
    "from numba import jit ,f8\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import sklearn\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver & Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def generate_grid(n,bc,ic=0):\n",
    "    #n=> Number of interior nodes\n",
    "\n",
    "    A = np.ones((n+2,n+2),dtype=np.float32) * ic\n",
    "    A[0,0]=A[-1,-1]=A[0,-1]=A[-1,0]=0\n",
    "    A[0,1:-1]=bc[2]    # switch the top and bottom wall since we start the iterations from top\n",
    "    A[1:-1,-1]=bc[1]\n",
    "    A[-1,1:-1]=bc[0]\n",
    "    A[1:-1,0]=bc[3]\n",
    "\n",
    "    return A\n",
    "\n",
    "@jit(nopython=True)\n",
    "def update_grid_col(grid,x,n):\n",
    "    #first half step update\n",
    "    #x col values ;\n",
    "    #n col number \n",
    "    grid[1:-1,n] = x\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def update_grid_row(grid,x,n):\n",
    "    #second half step update\n",
    "    #x row values ;\n",
    "    #n col number \n",
    "    grid[n,1:-1] = x\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_first_half(A,i,j,lam):\n",
    "    #calculate the ADI explicit part of the equation first half step\n",
    "    if j==1 :\n",
    "        return  lam * A[j][i-1] + 2 *(1-lam) * A[j][i] + lam * A[j][i+1] + lam * A[j-1][i]\n",
    "    elif j== A.shape[0]-2 :\n",
    "        return  lam * A[j][i-1] + 2 *(1-lam) * A[j][i] + lam * A[j][i+1] + lam * A[j+1][i]\n",
    "    else  :\n",
    "        return  lam * A[j][i-1] + 2 *(1-lam) * A[j][i] + lam * A[j][i+1]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def calculate_second_half(A,i,j,lam):\n",
    "    #calculate the ADI explicit part of the equation second half step\n",
    "    if i==1 :\n",
    "        return  lam * A[j-1][i] + 2 *(1-lam) * A[j][i] + lam * A[j+1][i] + lam * A[j][i-1]\n",
    "    elif i== A.shape[0]-2 :\n",
    "        return  lam * A[j-1][i] + 2 *(1-lam) * A[j][i] + lam * A[j+1][i] + lam * A[j][i+1]\n",
    "    else  :\n",
    "        return  lam * A[j-1][i] + 2 *(1-lam) * A[j][i] + lam * A[j+1][i]\n",
    "\n",
    "@jit(nopython=True)\n",
    "def generate_TDM(Lambda,N=3):\n",
    "    a = np.ones(N-1,dtype=np.float32)*-Lambda \n",
    "    b =np.ones(N,dtype=np.float32) * 2*(Lambda+1) \n",
    "    return a,b,a\n",
    "\n",
    "@jit(f8[:](f8[:],f8[:],f8[:],f8[:]))\n",
    "def TDMA_solver(a0,b0,c0,d0):\n",
    "    a =np.copy(a0)\n",
    "    b =np.copy(b0)\n",
    "    c =np.copy(c0)\n",
    "    d =np.copy(d0)\n",
    "    ld = len(d)\n",
    "\n",
    "    for i in range(1,ld):\n",
    "        w    = a[i-1]/b[i-1]\n",
    "        b[i] = b[i]- w * c[i-1]\n",
    "        d[i] = d[i] -w * d[i-1]\n",
    "    \n",
    "    R=b\n",
    "    R[-1]=d[-1]/b[-1]\n",
    "    \n",
    "    for i in range(ld-2,-1,-1):\n",
    "        R[i]= (d[i]-c[i]*R[i+1]) /b[i]\n",
    "        \n",
    "    return R\n",
    "\n",
    "@jit(nopython=True)\n",
    "def ADI_first_half_step(grid,Lambda,a,b,c):\n",
    "    #apply ADI for single step\n",
    "\n",
    "    N = grid.shape[0]\n",
    "\n",
    "    ##First half step\n",
    "    for i in range(1,N-1):\n",
    "\n",
    "        # initialize explicit side of equation to zeros\n",
    "        d = np.zeros((N-2))\n",
    "\n",
    "        #move vertically implcitly and calculate horizontally explicitly\n",
    "        for j in range(1,N-1):\n",
    "            d[j-1] =calculate_first_half(grid,i,j,Lambda)\n",
    "\n",
    "        x = TDMA_solver(a,b,c,d)\n",
    "\n",
    "        grid = update_grid_col(grid,x,i)\n",
    "\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def ADI_second_half_step(grid,Lambda,a,b,c):\n",
    "    #apply ADI for single step\n",
    "\n",
    "    N = grid.shape[1]\n",
    "\n",
    "    ##Second half step\n",
    "    for i in range(1,N-1):\n",
    "\n",
    "        # initialize explicit side of equation to zeros\n",
    "        d = np.zeros((N-2))\n",
    "\n",
    "        #move horizontally implcitly and calculate vertically explicitly\n",
    "        for j in range(1,N-1):\n",
    "            d[j-1] =calculate_second_half(grid,j,i,Lambda)\n",
    "\n",
    "        x = TDMA_solver(a,b,c,d)\n",
    "\n",
    "        grid = update_grid_row(grid,x,i)\n",
    "\n",
    "    return grid\n",
    "\n",
    "@jit(nopython=True)\n",
    "def solve(grid,Lambda=1,iters=1,steps=False) :\n",
    "    if steps :\n",
    "        #save intermeidate steps\n",
    "\n",
    "        #(frames,height,width)\n",
    "        grids = np.zeros((iters+1, grid.shape[0],grid.shape[1]),dtype=np.float32)\n",
    "        grids[0,:,:]=grid\n",
    "        a,b,c = generate_TDM(Lambda,grid.shape[0]-2)\n",
    "        #apply ADI iteratively\n",
    "        for i in range(1,iters+1):\n",
    "            grids[i,:,:] = ADI_first_half_step(grid,Lambda,a,b,c)\n",
    "            grids[i,:,:] = ADI_second_half_step(grid,Lambda,a,b,c)\n",
    "\n",
    "\n",
    "    else : \n",
    "        grids = np.zeros((2,grid.shape[0],grid.shape[1]),dtype=np.float32)\n",
    "        #Show final step only\n",
    "        grids[0,:,:]=grid\n",
    "        a,b,c = generate_TDM(Lambda,grid.shape[0]-2)\n",
    "        #apply ADI iteratively\n",
    "        for i in range(iters):\n",
    "            grids[1,:,:] = ADI_first_half_step(grid,Lambda,a,b,c)\n",
    "            grids[1,:,:] = ADI_second_half_step(grid,Lambda,a,b,c)\n",
    "\n",
    "    return grids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pad_grids(grids,Lambda):\n",
    "    grids[:,0,0]=grids[:,-1,0]=grids[:,0,-1]=grids[:,-1,-1]=Lambda * 1000\n",
    "    return grids\n",
    "\n",
    "@ray.remote\n",
    "def solve_permutation(n,iters,permutation):\n",
    "    Lambda,bc1,bc2,bc3,bc4,ic = permutation\n",
    "    grid = generate_grid(n-2,bc=(bc1,bc2,bc3,bc4),ic=ic)\n",
    "    ADIsoltuion = solve(grid.copy(),Lambda = Lambda,iters =iters ,steps=True)\n",
    "    return  np.array(pad_grids(ADIsoltuion,Lambda)).reshape(ADIsoltuion.shape[0],ADIsoltuion.shape[1],ADIsoltuion.shape[2],1)\n",
    "\n",
    "\n",
    "def generate_data(N,iters,permutations):\n",
    "    '''\n",
    "    Input : \n",
    "    N            : size of grid\n",
    "    iters        : max iterations done by solver\n",
    "    permutations : the solution parameters as a set of permutation (Lambda,bc1,..bc4,ic0)\n",
    "    \n",
    "    Output:\n",
    "    solution with shape (iters+1,N,N)\n",
    "    '''\n",
    "    data = [(solve_permutation.remote(N,iters,i)) for i in (permutations) ]\n",
    "    return np.array([ray.get(datalet) for datalet in (data)])\n",
    "    \n",
    "\n",
    "def generate_data_random_permutations(lR=(0,0.25),tR=(0,1000),batches =1,batch_size=32,seed =42,split=1 ):\n",
    "    '''\n",
    "    Input:\n",
    "    *Lambda range\n",
    "    *Temperature range\n",
    "    *Size of data\n",
    "    \n",
    "    Output:\n",
    "    *Generate a generator of size with elements of (Lambda,bc1,..bc4,ic0)\n",
    "    '''\n",
    "    np.random.seed(seed);\n",
    "    lr = np.random.randint(low = tR[0] , high = tR[1] ,size=(batches,batch_size,6)).astype('float')\n",
    "    lr[:,:,0] = ((lR[1]-lR[0])*(lr[:,:,0]-tR[0]))/(tR[1]-tR[0])\n",
    "    return lr\n",
    "\n",
    "\n",
    "def generate_data_batches(N=50,\n",
    "                          lR=(0,0.5),\n",
    "                          tR=(0,100),\n",
    "                          max_iters=10,\n",
    "                          seed=42,\n",
    "                          steps=1,\n",
    "                          step_size=1,\n",
    "                          batch_size=32,\n",
    "                          batches=100,\n",
    "                          progress=True,\n",
    "                          key_bias =0,\n",
    "                          save_file = None):\n",
    "    '''\n",
    "    return dictionary with key of the batch number\n",
    "    '''\n",
    "    if save_file is not None : \n",
    "        hf = h5py.File(save_file,'w')\n",
    "\n",
    "    np.random.seed(seed)\n",
    "    perms = generate_data_random_permutations(lR=lR,tR=tR,batch_size=batch_size,batches=batches,seed=seed)\n",
    "    iters_list=  np.random.randint(low=step_size,high=max_iters-step_size*(steps-1)+1,size=batches)\n",
    "\n",
    "    #scaling \n",
    "    mean = (tR[1]-tR[0])/2\n",
    "    std  = mean/2\n",
    "    data={}\n",
    "    \n",
    "    for batch_num in tqdm(range(batches)):\n",
    "        \n",
    "        iter_n = iters_list[batch_num]\n",
    "        \n",
    "        generated_data = generate_data(N,iter_n+steps*step_size,perms[batch_num])\n",
    "        extract_index = np.arange(iter_n-step_size,iter_n+step_size*steps,step_size)\n",
    "#         yield(extract_index)\n",
    "        generated_data = generated_data[:,extract_index,:,:,:]\n",
    "        \n",
    "        if save_file is None :\n",
    "            data[f'{batch_num + key_bias}'] = (generated_data -mean) /std\n",
    "        else : \n",
    "            hf.create_dataset(f'{batch_num}',data = data[batch_num] , compression ='gzip')\n",
    "    \n",
    "    if save_file is not None :hf.close()\n",
    "    else : return data\n",
    "\n",
    "    \n",
    "def data_generator(data):\n",
    "    '''\n",
    "    input : data dictionary (batch number :5D tensor data)\n",
    "    output: input , target values\n",
    "    '''\n",
    "    batches = len(data.keys())\n",
    "    batch_size = len(data['0'])\n",
    "    batch_counter= 0\n",
    "    \n",
    "    while True:\n",
    "        x,y = data[f'{batch_counter}'][:,:-1,:,:,:],data[f'{batch_counter}'][:,-1:,:,:,:]\n",
    "\n",
    "        batch_counter += 1\n",
    "        yield x,y\n",
    "        if batch_counter == batches:batch_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-20T07:02:16.625562Z",
     "start_time": "2020-10-20T07:01:54.600362Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-14 05:51:19,448\tINFO services.py:1092 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n",
      "2020-11-14 05:51:19,453\tWARNING services.py:1560 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 16106127360 bytes available. This may slow down performance! You may be able to free up space by deleting files in /dev/shm or terminating any running plasma_store_server processes. If you are inside a Docker container, you may need to pass an argument with the flag '--shm-size' to 'docker run'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.17.0.6',\n",
       " 'raylet_ip_address': '172.17.0.6',\n",
       " 'redis_address': '172.17.0.6:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-11-14_05-51-18_608336_6806/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-11-14_05-51-18_608336_6806/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-11-14_05-51-18_608336_6806',\n",
       " 'metrics_export_port': 43426,\n",
       " 'node_id': '96a989bcf3902062d87392efb24bcd142d40429a'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-20T07:04:32.404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb15e98a89e349c7bd9de8fa6a07083e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=9000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_batches =generate_data_batches(N=12,\n",
    "                                          lR=(0,1),\n",
    "                                          tR=(0,1_000),\n",
    "                                          max_iters=1000,\n",
    "                                          seed=42,\n",
    "                                          batch_size=32,\n",
    "                                          step_size= 100,\n",
    "                                          steps=1,\n",
    "                                          batches=9000,\n",
    "                                          progress=True)\n",
    "#                                           save_file = 'N=100x100 batch_size=64 batches=5000 max_iters=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-20T07:04:32.404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211d1fad452742a994aa487da112c60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_batches_bias =generate_data_batches(N=12,\n",
    "                                          lR=(0,1),\n",
    "                                          tR=(0,1_000),\n",
    "                                          max_iters=120,\n",
    "                                          seed=42,\n",
    "                                          batch_size=32,\n",
    "                                          step_size= 100,\n",
    "                                          steps=1,\n",
    "                                          batches =1_000,\n",
    "                                          key_bias = 9_000,\n",
    "                                          progress = True)\n",
    "#                                           save_file = 'N=100x100 batch_size=64 batches=5000 max_iters=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T06:28:14.703199Z",
     "start_time": "2020-10-15T06:28:10.596157Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d561aaf1774b439a80104132d83fea35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validation_data_batches =generate_data_batches(N=12,\n",
    "                                              lR=(0,1),\n",
    "                                              tR=(0,1_000),\n",
    "                                              max_iters=1000,\n",
    "                                              seed=0,\n",
    "                                              batch_size=32,\n",
    "                                              step_size= 100,\n",
    "                                              steps=1,\n",
    "                                              batches=50,\n",
    "                                              progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def conv(x,f,k):\n",
    "    x = TimeDistributed(Conv2D(f,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return x\n",
    "    \n",
    "def deconv(x,f,k):\n",
    "    x = TimeDistributed(Conv2DTranspose(f,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "def dense_block(tensor, f, r,k):\n",
    "    for _ in range(r):\n",
    "        x = conv(tensor, f=4*f, k=1)\n",
    "        x = conv(x, f=f, k=k)\n",
    "        tensor = Concatenate()([tensor, x])\n",
    "    return tensor\n",
    "\n",
    "def inv_dense_block(tensor, f, r,k):\n",
    "    for _ in range(r):\n",
    "        x = deconv(tensor, f=4*f, k=1)\n",
    "        x = deconv(x, f=f, k=k)\n",
    "        tensor = Concatenate()([tensor, x])\n",
    "    return tensor\n",
    "\n",
    "def transition(x,s):\n",
    "    ff = int(tensorflow.keras.backend.int_shape(x)[-1] * 0.5)\n",
    "    m0 = TimeDistributed(Conv2D(ff,(1,1),strides=2*s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return m0\n",
    "\n",
    "def inv_transition(x,s):\n",
    "    ff = int(tensorflow.keras.backend.int_shape(x)[-1] * 0.5)\n",
    "    m0 = TimeDistributed(Conv2DTranspose(ff,(1,1),strides=2*s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return m0\n",
    "\n",
    "\n",
    "def dfn():\n",
    "    \n",
    "    k=3\n",
    "    s=1;\n",
    "    LR=1e-4\n",
    "    \n",
    "    r1,r2,r3 = 2 , 4 ,8\n",
    "    f0,f1,f2,f3 = 128,32,32,32\n",
    "    l1,l2 = 128 ,64\n",
    "\n",
    "    x = Input(shape=(None, None,None, 1))\n",
    "    c0 = TimeDistributed(Conv2D(f0,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "########################################################################################################    \n",
    "    e1 = dense_block(c0,f1,r=r1,k=k);m1 = transition(e1,s)\n",
    "    e2 = dense_block(m1,f2,r=r2,k=k);m2 = transition(e2,s)\n",
    "    e3 = dense_block(m2,f3,r=r3,k=k);\n",
    "########################################################################################################\n",
    "    e = ConvLSTM2D(l1,(2,2),padding='same',return_sequences=True)(e3)\n",
    "    b = ConvLSTM2D(l2,(2,2),padding='same',return_sequences=True)(e)\n",
    "    d = ConvLSTM2D(l1,(2,2),padding='same',return_sequences=True)(b)\n",
    "########################################################################################################\n",
    "    d1 = inv_dense_block(d ,f3,r=r3,k=k);m1 = inv_transition(d1,s)\n",
    "    d2 = inv_dense_block(m1,f2,r=r2,k=k);m2 = inv_transition(d2,s)\n",
    "    d3 = inv_dense_block(m2,f1,r=r1,k=k);\n",
    "########################################################################################################\n",
    "    out = conv(d3,f=1,k=1)\n",
    "    model = Model(x,out)\n",
    "    optimizer = Adam(learning_rate=LR)\n",
    "    model.compile(loss='mae',optimizer=optimizer,metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "model = dfn()\n",
    "# model.summary()\n",
    "# keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T06:48:10.103493Z",
     "start_time": "2020-10-15T06:48:10.090529Z"
    }
   },
   "outputs": [],
   "source": [
    "history={}\n",
    "i = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 1196s 117ms/step - loss: 0.1300 - mse: 0.1154 - val_loss: 0.0571 - val_mse: 0.0426\n",
      "\n",
      "Epoch 00001: saving model to step=100 12x12.h5\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 1150s 115ms/step - loss: 0.0469 - mse: 0.0420 - val_loss: 0.0479 - val_mse: 0.0407\n",
      "\n",
      "Epoch 00002: saving model to step=100 12x12.h5\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 1132s 113ms/step - loss: 0.0430 - mse: 0.0389 - val_loss: 0.0277 - val_mse: 0.0160\n",
      "\n",
      "Epoch 00003: saving model to step=100 12x12.h5\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 1164s 116ms/step - loss: 0.0176 - mse: 0.0053 - val_loss: 0.0134 - val_mse: 0.0012\n",
      "\n",
      "Epoch 00004: saving model to step=100 12x12.h5\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 1174s 117ms/step - loss: 0.0109 - mse: 0.0012 - val_loss: 0.0099 - val_mse: 0.0011\n",
      "\n",
      "Epoch 00005: saving model to step=100 12x12.h5\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 1183s 118ms/step - loss: 0.0097 - mse: 9.9398e-04 - val_loss: 0.0092 - val_mse: 8.4499e-04\n",
      "\n",
      "Epoch 00006: saving model to step=100 12x12.h5\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 1185s 118ms/step - loss: 0.0092 - mse: 8.6380e-04 - val_loss: 0.0099 - val_mse: 7.5870e-04\n",
      "\n",
      "Epoch 00007: saving model to step=100 12x12.h5\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 1178s 118ms/step - loss: 0.0087 - mse: 7.7991e-04 - val_loss: 0.0113 - val_mse: 7.6366e-04\n",
      "\n",
      "Epoch 00008: saving model to step=100 12x12.h5\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 1163s 116ms/step - loss: 0.0082 - mse: 7.1989e-04 - val_loss: 0.0065 - val_mse: 7.8384e-04\n",
      "\n",
      "Epoch 00009: saving model to step=100 12x12.h5\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 1158s 116ms/step - loss: 0.0078 - mse: 6.7342e-04 - val_loss: 0.0128 - val_mse: 7.8525e-04\n",
      "\n",
      "Epoch 00010: saving model to step=100 12x12.h5\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 1166s 117ms/step - loss: 0.0076 - mse: 6.2776e-04 - val_loss: 0.0061 - val_mse: 5.8252e-04\n",
      "\n",
      "Epoch 00011: saving model to step=100 12x12.h5\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 1183s 118ms/step - loss: 0.0073 - mse: 5.4225e-04 - val_loss: 0.0098 - val_mse: 5.6263e-04\n",
      "\n",
      "Epoch 00012: saving model to step=100 12x12.h5\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 1182s 118ms/step - loss: 0.0067 - mse: 3.7050e-04 - val_loss: 0.0117 - val_mse: 5.2477e-04\n",
      "\n",
      "Epoch 00013: saving model to step=100 12x12.h5\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 1141s 114ms/step - loss: 0.0064 - mse: 2.9205e-04 - val_loss: 0.0052 - val_mse: 3.4505e-04\n",
      "\n",
      "Epoch 00014: saving model to step=100 12x12.h5\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 1011s 101ms/step - loss: 0.0062 - mse: 2.6995e-04 - val_loss: 0.0074 - val_mse: 3.5456e-04\n",
      "\n",
      "Epoch 00015: saving model to step=100 12x12.h5\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 0.0061 - mse: 2.4221e-04 - val_loss: 0.0079 - val_mse: 6.6949e-04\n",
      "\n",
      "Epoch 00016: saving model to step=100 12x12.h5\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 1014s 101ms/step - loss: 0.0059 - mse: 2.3137e-04 - val_loss: 0.0097 - val_mse: 6.9881e-04\n",
      "\n",
      "Epoch 00017: saving model to step=100 12x12.h5\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 1011s 101ms/step - loss: 0.0057 - mse: 2.1813e-04 - val_loss: 0.0097 - val_mse: 4.5172e-04\n",
      "\n",
      "Epoch 00018: saving model to step=100 12x12.h5\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 1013s 101ms/step - loss: 0.0055 - mse: 1.8244e-04 - val_loss: 0.0068 - val_mse: 4.2741e-04\n",
      "\n",
      "Epoch 00019: saving model to step=100 12x12.h5\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 1009s 101ms/step - loss: 0.0056 - mse: 1.8100e-04 - val_loss: 0.0068 - val_mse: 6.1836e-04\n",
      "\n",
      "Epoch 00020: saving model to step=100 12x12.h5\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 1006s 101ms/step - loss: 0.0053 - mse: 1.8565e-04 - val_loss: 0.0077 - val_mse: 3.7954e-04\n",
      "\n",
      "Epoch 00021: saving model to step=100 12x12.h5\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 1009s 101ms/step - loss: 0.0053 - mse: 1.6885e-04 - val_loss: 0.0077 - val_mse: 5.8227e-04\n",
      "\n",
      "Epoch 00022: saving model to step=100 12x12.h5\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 1012s 101ms/step - loss: 0.0053 - mse: 1.7147e-04 - val_loss: 0.0067 - val_mse: 3.6333e-04\n",
      "\n",
      "Epoch 00023: saving model to step=100 12x12.h5\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 1009s 101ms/step - loss: 0.0052 - mse: 1.5507e-04 - val_loss: 0.0065 - val_mse: 6.3039e-04\n",
      "\n",
      "Epoch 00024: saving model to step=100 12x12.h5\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 1002s 100ms/step - loss: 0.0051 - mse: 1.5945e-04 - val_loss: 0.0062 - val_mse: 3.1689e-04\n",
      "\n",
      "Epoch 00025: saving model to step=100 12x12.h5\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 1009s 101ms/step - loss: 0.0050 - mse: 1.3372e-04 - val_loss: 0.0058 - val_mse: 3.7366e-04\n",
      "\n",
      "Epoch 00026: saving model to step=100 12x12.h5\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 1015s 101ms/step - loss: 0.0049 - mse: 1.3362e-04 - val_loss: 0.0079 - val_mse: 3.7861e-04\n",
      "\n",
      "Epoch 00027: saving model to step=100 12x12.h5\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 1012s 101ms/step - loss: 0.0048 - mse: 1.2393e-04 - val_loss: 0.0074 - val_mse: 4.1094e-04\n",
      "\n",
      "Epoch 00028: saving model to step=100 12x12.h5\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 1013s 101ms/step - loss: 0.0047 - mse: 1.2180e-04 - val_loss: 0.0070 - val_mse: 3.7298e-04\n",
      "\n",
      "Epoch 00029: saving model to step=100 12x12.h5\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 1004s 100ms/step - loss: 0.0046 - mse: 1.2223e-04 - val_loss: 0.0045 - val_mse: 2.5271e-04\n",
      "\n",
      "Epoch 00030: saving model to step=100 12x12.h5\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 1004s 100ms/step - loss: 0.0046 - mse: 1.1609e-04 - val_loss: 0.0079 - val_mse: 4.8296e-04\n",
      "\n",
      "Epoch 00031: saving model to step=100 12x12.h5\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 1012s 101ms/step - loss: 0.0046 - mse: 1.1841e-04 - val_loss: 0.0062 - val_mse: 4.9038e-04\n",
      "\n",
      "Epoch 00032: saving model to step=100 12x12.h5\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 1011s 101ms/step - loss: 0.0046 - mse: 1.2055e-04 - val_loss: 0.0055 - val_mse: 1.4552e-04\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "\n",
      "Epoch 00033: saving model to step=100 12x12.h5\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 1012s 101ms/step - loss: 0.0026 - mse: 4.5322e-05 - val_loss: 0.0038 - val_mse: 7.4064e-05\n",
      "\n",
      "Epoch 00034: saving model to step=100 12x12.h5\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 1011s 101ms/step - loss: 0.0025 - mse: 3.9503e-05 - val_loss: 0.0033 - val_mse: 1.7515e-04\n",
      "\n",
      "Epoch 00035: saving model to step=100 12x12.h5\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 1004s 100ms/step - loss: 0.0025 - mse: 4.1499e-05 - val_loss: 0.0026 - val_mse: 6.9083e-05\n",
      "\n",
      "Epoch 00036: saving model to step=100 12x12.h5\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 1002s 100ms/step - loss: 0.0025 - mse: 3.5642e-05 - val_loss: 0.0034 - val_mse: 1.3223e-04\n",
      "\n",
      "Epoch 00037: saving model to step=100 12x12.h5\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 1011s 101ms/step - loss: 0.0025 - mse: 3.8376e-05 - val_loss: 0.0030 - val_mse: 9.5267e-05\n",
      "\n",
      "Epoch 00038: saving model to step=100 12x12.h5\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 1013s 101ms/step - loss: 0.0024 - mse: 3.5201e-05 - val_loss: 0.0038 - val_mse: 1.5779e-04\n",
      "\n",
      "Epoch 00039: saving model to step=100 12x12.h5\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 1006s 101ms/step - loss: 0.0025 - mse: 3.6800e-05 - val_loss: 0.0038 - val_mse: 8.6935e-05\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "\n",
      "Epoch 00040: saving model to step=100 12x12.h5\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 1005s 100ms/step - loss: 0.0016 - mse: 1.8743e-05 - val_loss: 0.0021 - val_mse: 2.2226e-05\n",
      "\n",
      "Epoch 00041: saving model to step=100 12x12.h5\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 1004s 100ms/step - loss: 0.0016 - mse: 1.5792e-05 - val_loss: 0.0020 - val_mse: 2.0245e-05\n",
      "\n",
      "Epoch 00042: saving model to step=100 12x12.h5\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 1006s 101ms/step - loss: 0.0016 - mse: 1.5241e-05 - val_loss: 0.0020 - val_mse: 1.9641e-05\n",
      "\n",
      "Epoch 00043: saving model to step=100 12x12.h5\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 1003s 100ms/step - loss: 0.0015 - mse: 1.5120e-05 - val_loss: 0.0022 - val_mse: 2.0749e-05\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "\n",
      "Epoch 00044: saving model to step=100 12x12.h5\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 1007s 101ms/step - loss: 0.0012 - mse: 1.0082e-05 - val_loss: 0.0016 - val_mse: 1.9598e-05\n",
      "\n",
      "Epoch 00045: saving model to step=100 12x12.h5\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 1011s 101ms/step - loss: 0.0012 - mse: 9.0932e-06 - val_loss: 0.0016 - val_mse: 1.8935e-05\n",
      "\n",
      "Epoch 00046: saving model to step=100 12x12.h5\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 0.0012 - mse: 8.6690e-06 - val_loss: 0.0016 - val_mse: 1.7346e-05\n",
      "\n",
      "Epoch 00047: saving model to step=100 12x12.h5\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 0.0012 - mse: 8.4443e-06 - val_loss: 0.0016 - val_mse: 1.5894e-05\n",
      "\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "\n",
      "Epoch 00048: saving model to step=100 12x12.h5\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 0.0011 - mse: 7.2268e-06 - val_loss: 0.0015 - val_mse: 1.8250e-05\n",
      "\n",
      "Epoch 00049: saving model to step=100 12x12.h5\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 1002s 100ms/step - loss: 0.0010 - mse: 6.8362e-06 - val_loss: 0.0014 - val_mse: 1.7767e-05\n",
      "\n",
      "Epoch 00050: saving model to step=100 12x12.h5\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 1006s 101ms/step - loss: 0.0010 - mse: 6.5970e-06 - val_loss: 0.0014 - val_mse: 1.7308e-05\n",
      "\n",
      "Epoch 00051: saving model to step=100 12x12.h5\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 0.0010 - mse: 6.4035e-06 - val_loss: 0.0014 - val_mse: 1.7455e-05\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "\n",
      "Epoch 00052: saving model to step=100 12x12.h5\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 9.7206e-04 - mse: 6.0638e-06 - val_loss: 0.0011 - val_mse: 2.1301e-05\n",
      "\n",
      "Epoch 00053: saving model to step=100 12x12.h5\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 9.6355e-04 - mse: 5.9200e-06 - val_loss: 0.0011 - val_mse: 2.0908e-05\n",
      "\n",
      "Epoch 00054: saving model to step=100 12x12.h5\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 1009s 101ms/step - loss: 9.5846e-04 - mse: 5.7849e-06 - val_loss: 0.0011 - val_mse: 2.0346e-05\n",
      "\n",
      "Epoch 00055: saving model to step=100 12x12.h5\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 1004s 100ms/step - loss: 9.5363e-04 - mse: 5.6729e-06 - val_loss: 0.0011 - val_mse: 2.0238e-05\n",
      "\n",
      "Epoch 00056: saving model to step=100 12x12.h5\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 1002s 100ms/step - loss: 9.4938e-04 - mse: 5.5817e-06 - val_loss: 0.0011 - val_mse: 2.0332e-05\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-06.\n",
      "\n",
      "Epoch 00057: saving model to step=100 12x12.h5\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 1006s 101ms/step - loss: 9.2568e-04 - mse: 5.4973e-06 - val_loss: 0.0011 - val_mse: 1.7372e-05\n",
      "\n",
      "Epoch 00058: saving model to step=100 12x12.h5\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 1008s 101ms/step - loss: 9.2060e-04 - mse: 5.3325e-06 - val_loss: 0.0011 - val_mse: 1.7102e-05\n",
      "\n",
      "Epoch 00059: saving model to step=100 12x12.h5\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 1010s 101ms/step - loss: 9.1774e-04 - mse: 5.2609e-06 - val_loss: 0.0010 - val_mse: 1.6960e-05\n",
      "\n",
      "Epoch 00060: ReduceLROnPlateau reducing learning rate to 7.81249980263965e-07.\n",
      "\n",
      "Epoch 00060: saving model to step=100 12x12.h5\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 1009s 101ms/step - loss: 9.0667e-04 - mse: 5.2922e-06 - val_loss: 0.0010 - val_mse: 1.4965e-05\n",
      "\n",
      "Epoch 00061: saving model to step=100 12x12.h5\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 1006s 101ms/step - loss: 9.0275e-04 - mse: 5.1493e-06 - val_loss: 0.0010 - val_mse: 1.4736e-05\n",
      "\n",
      "Epoch 00062: saving model to step=100 12x12.h5\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 1006s 101ms/step - loss: 9.0113e-04 - mse: 5.1062e-06 - val_loss: 9.9932e-04 - val_mse: 1.4571e-05\n",
      "\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 3.906249901319825e-07.\n",
      "\n",
      "Epoch 00063: saving model to step=100 12x12.h5\n",
      "Epoch 00063: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1a09b4efd0>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_logger = tensorflow.keras.callbacks.CSVLogger('train step=100 12x12.log')\n",
    "early_stopping = tensorflow.keras.callbacks.EarlyStopping(monitor='loss',min_delta=5e-5, patience=5, verbose=1, mode='auto',baseline=None, restore_best_weights=False)\n",
    "reduce_lr_callback = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = 'loss',factor = 0.5,patience = 3,verbose = 1,cooldown=1,min_delta = 1e-4,min_lr=1e-8 )\n",
    "model_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint('step=100 12x12.h5', monitor='loss', verbose=1, save_best_only=False,save_weights_only=False, mode='auto', save_freq='epoch',)\n",
    "model.fit(data_generator({**train_data_batches,**train_data_batches_bias}),\n",
    "          validation_data=data_generator(validation_data_batches),\n",
    "          steps_per_epoch=len({**train_data_batches,**train_data_batches_bias}),\n",
    "          validation_steps=len(validation_data_batches),\n",
    "          verbose=1,\n",
    "          epochs=100,\n",
    "          callbacks=[reduce_lr_callback,early_stopping,csv_logger,model_checkpoint_callback],\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('step=100 12x12 loss=9.0113e-4 9.9932e-4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:59:56.465051Z",
     "start_time": "2020-10-17T14:59:55.611505Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:59:57.984142Z",
     "start_time": "2020-10-17T14:59:57.671939Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "def show_heat_maps(*grids,annotate=False,save=None , rc=None,figsize=(30,10),cbar_location='left'):\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if rc is  None : rc=(1,len(grids))\n",
    "    grid = ImageGrid(fig, 111, nrows_ncols=rc,axes_pad=0.25,share_all=True,cbar_location=cbar_location,cbar_mode=\"single\",cbar_size=\"5%\",cbar_pad=0.25,)\n",
    "    for ax,g in zip(grid,grids):\n",
    "        im = ax.imshow(g[0]) ; \n",
    "        ax.title.set_text(g[1])\n",
    "        if annotate:\n",
    "            N,M = int(g[0].shape[0]),int(g[0].shape[1])\n",
    "            for k in range(N):\n",
    "                for j in range(M):\n",
    "                    text1 = ax.text(j, k, np.round(g[0][k, j],1),ha=\"center\", va=\"center\", color=\"w\",fontsize=20)\n",
    "\n",
    "\n",
    "        ax.cax.colorbar(im)\n",
    "        ax.cax.toggle_label(True)\n",
    "    \n",
    "    if save is not None : plt.savefig(save)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T15:03:22.983589Z",
     "start_time": "2020-10-17T15:03:17.236703Z"
    }
   },
   "outputs": [],
   "source": [
    "import  tensorflow\n",
    "loaded_model = model #tensorflow.keras.models.load_model('48x48 loss=6.152e-4 7.5453e-4.h5')\n",
    "loaded_model2 = model # model_scaled #tensorflow.keras.models.load_model('bias 100x100 step=10 loss=0.0012 model 27th october model.h5')\n",
    "\n",
    "# loaded_model2 = keras.models.load_model('100x100 step=10 loss=0.008 model 17th october model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137eaaa0b3a649908bea1f5c8672a8c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=600, continuous_update=False, description='bc1 # ', layout=Layout(height…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "layout = ipywidgets.Layout(width= '100%',height='20px')\n",
    "\n",
    "bc1 = ipywidgets.IntSlider(min=0,max=1000,value = 600,step=1,description='bc1 # ' ,layout=layout,continuous_update=False)\n",
    "bc2 = ipywidgets.IntSlider(min=0,max=1000,value=500,step=1,description='bc2 # ' ,layout=layout,continuous_update=False)\n",
    "bc3 = ipywidgets.IntSlider(min=0,max=1000,value=100,step=1,description='bc3 # ' ,layout=layout,continuous_update=False)\n",
    "bc4 = ipywidgets.IntSlider(min=0,max=1000,step=1,value=400,description='bc4 # ' ,layout=layout,continuous_update=False)\n",
    "ic0 = ipywidgets.IntSlider(min=0,max=1000,step=1,value=100,description='ic # ' ,layout=layout,continuous_update=False)\n",
    "lam = ipywidgets.FloatSlider(min=0,max=0.5,value=0.125,step=0.00001,description='lambda # ' ,layout=layout,continuous_update=False,readout_format='.5f')\n",
    "\n",
    "\n",
    "t00 = ipywidgets.IntSlider(min=0,max=10_000,step=1,value=0,description='t00 # ' ,layout=layout,continuous_update=False)\n",
    "t0f = ipywidgets.IntSlider(min=0,max=50_000,step=1,value=t00.value+100,description='t0f # ' ,layout=layout,continuous_update=False)\n",
    "\n",
    "@ipywidgets.interact(bc1=bc1,bc2=bc2,bc3=bc3,bc4=bc4,ic0=ic0,lam=lam,t00=t00,t0f=t0f,analyze=False,plot=False,save=False)\n",
    "def compare_solution(bc1,bc2,bc3,bc4,ic0,lam,t00,t0f,analyze=False,plot=False,save=False):\n",
    "    size = 12  ; mean = 5_00  ;  std  = 2_50 ; step = 10  ; total_step = 1\n",
    "   \n",
    "    '''\n",
    "    generate the adi solution in shape of \n",
    "    (frames , rows ,cols)\n",
    "    '''\n",
    "    tic = time.time()\n",
    "    \n",
    "    grid = generate_grid( size - 2 , bc =(bc1,bc2,bc3,bc4),ic=ic0)\n",
    "    adi_solution = solve(grid.copy(), iters = t00+step*total_step ,Lambda= lam ,steps=True)\n",
    "    toc = time.time()\n",
    "    \n",
    "    print(f'Numerical solution excuted in {(toc-tic)*1e3}ms')\n",
    "    \n",
    "    '''\n",
    "    model expects scaled input 5d tensor in shape of \n",
    "    ( sample size , frames number , rows , cols , channels )\n",
    "    standard scaling using mean = 500  ,std = 250\n",
    "    '''\n",
    "    if analyze :\n",
    "        # Preprocessing\n",
    "        model_input = pad_grids(adi_solution,lam)   #pad\n",
    "        model_input = ( adi_solution[t00:t00+1,:,:] - mean ) / std  #scale \n",
    "        model_input = model_input.reshape(1,1,size,size,1)        #reshape to 5d tensor\n",
    "\n",
    "        \n",
    "        plot_list =[]\n",
    "        \n",
    "        prediction_solutions = {}\n",
    "        \n",
    "        tic = time.time() ; \n",
    "        \n",
    "        prediction_solutions[0] = model_input ; \n",
    "        \n",
    "        for i in range(0,total_step+1):\n",
    "            prediction_solutions[i+1] = loaded_model.predict(prediction_solutions[i])\n",
    "        \n",
    "        for i in range(0,total_step+1):\n",
    "            correct    = (adi_solution[t00+step*(i)],f'$Step={t00+step*(i)}$')\n",
    "            prediction = ((prediction_solutions[i][0,0,:,:,0]*std )+mean , f'$Step={t00+step*(i)}$')\n",
    "            plot_list.append(correct)\n",
    "            plot_list.append(prediction)\n",
    "            print(i)\n",
    "        \n",
    "        \n",
    "        \n",
    "        if plot :\n",
    "            if save :path = f'bc:{bc1},{bc2},{bc3},{bc4},{ic0}-lam:{lam}-t00:{t00}.svg' \n",
    "            else: path = None\n",
    "            print('MAE error:',sklearn.metrics.mean_absolute_error(adi_solution[t00+step*(0+1),1:-1,1:-1],prediction_solutions[0][0,0,1:-1,1:-1,0]))\n",
    "            \n",
    "            show_heat_maps(\n",
    "                *plot_list,\n",
    "                annotate=True,\n",
    "                figsize=(50,50),\n",
    "                rc=(len(plot_list)//2,2),\n",
    "                cbar_location='bottom'\n",
    "#             save=path           \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, ''), (1, ''))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a =[1,'']\n",
    "b = [2,'']\n",
    "\n",
    "tuple(b),tuple(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tensorflow.keras.models.load_model('12 24 48 96 loss=0.0013.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-20T07:04:32.404Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data_batches =generate_data_batches(N=12,\n",
    "                                          lR=(0,1),\n",
    "                                          tR=(0,1_000),\n",
    "                                          max_iters=1000,\n",
    "                                          seed=192,\n",
    "                                          batch_size=1,\n",
    "                                          step_size= 100,\n",
    "                                          steps=1,\n",
    "                                          batches=1000,\n",
    "                                          progress=True)\n",
    "#                                           save_file = 'N=100x100 batch_size=64 batches=5000 max_iters=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 32s 31ms/step - loss: 0.0372 - mse: 0.0108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03718770667910576, 0.010795393027365208]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_generator(test_data_batches),steps=len(test_data_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.zeros(1000);std= np.zeros(1000)\n",
    "for bi in test_data_batches:\n",
    "    mean[int(bi)] = np.mean((test_data_batches_12x12[bi] *250 )+ 500) \n",
    "    std[int(bi)]= np.std((test_data_batches_12x12[bi]*250)+500)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.75358987426756"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mean)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
