{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load finite net data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('invBurg_train.npy')[:]\n",
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "x = x.reshape(2000,101,10,10,1)\n",
    "x = (x-mean)/std\n",
    "\n",
    "\n",
    "s,f,r,w,c = x.shape\n",
    "z = np.zeros((s,f,r+2,w+2,c))\n",
    "z[:,:,1:-1,1:-1,:]  = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8540c40c94db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "mpl.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"sans-serif\",\n",
    "    \"font.sans-serif\": [\"Helvetica\"]})\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 300\n",
    "mpl.rcParams.update({'font.size': 25})\n",
    "mpl.rcParams['axes.linewidth'] = 1\n",
    "from matplotlib import ticker\n",
    "formatter = ticker.ScalarFormatter(useMathText=True)\n",
    "formatter.set_scientific(True) \n",
    "\n",
    "\n",
    "a = np.load('invBurg_train.npy')[:]\n",
    "\n",
    "plt.figure(figsize=(10,10));plt.tight_layout()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(a[1]);plt.xlabel('$x$');plt.ylabel('$t$')\n",
    "plt.subplot(1,2,2);plt.imshow(a[50]);plt.xlabel('$x$');plt.ylabel('$t$')\n",
    "plt.savefig('burger.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128000, 101, 12, 12, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xr = np.copy(z)\n",
    "for  i in range(6) : xr= np.concatenate([xr,xr])\n",
    "    \n",
    "xr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_batches(input_data,\n",
    "                          steps=1,\n",
    "                          seed=42,\n",
    "                          max_iters = 100,\n",
    "                          batch_size=32,\n",
    "                          batches=100,\n",
    "                          progress=True,\n",
    "                          step_size = 10,\n",
    "                          key_bias=0,\n",
    "                          save_file = None):\n",
    "    '''\n",
    "    return dictionary with key of the batch number\n",
    "    '''\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    iters_list=  np.random.randint(low=step_size,high=max_iters-step_size*(steps-1)+1,size=batches)\n",
    "\n",
    "    #scaling \n",
    "    mean = 0 #(tR[1]-tR[0])/2\n",
    "    std  = 1 #mean/2\n",
    "    data={}\n",
    "    \n",
    "    for batch_num in tqdm(range(batches)):\n",
    "        \n",
    "        iter_n = iters_list[batch_num]\n",
    "        extract_index = np.arange(iter_n-step_size,iter_n+step_size*steps,step_size)\n",
    "        generated_data = input_data[batch_num:batch_num+batch_size,extract_index,:,:,:]\n",
    "#         print(batch_num,batch_num+batch_size)\n",
    "#         print(generated_data)\n",
    "#         break\n",
    "        if save_file is None :\n",
    "            data[f'{batch_num + key_bias}'] = (generated_data) \n",
    "        else : \n",
    "            hf.create_dataset(f'{batch_num}',data = data[batch_num] , compression ='gzip')\n",
    "    \n",
    "    if save_file is not None :hf.close()\n",
    "    else : return data\n",
    "\n",
    "    \n",
    "def data_generator(data):\n",
    "    '''\n",
    "    input : data dictionary (batch number :5D tensor data)\n",
    "    output: input , target values\n",
    "    '''\n",
    "    batches = len(data.keys())\n",
    "    batch_size = len(data['0'])\n",
    "    batch_counter= 0\n",
    "    \n",
    "    while True:\n",
    "        x,y = data[f'{batch_counter}'][:,:-1,:,:,:],data[f'{batch_counter}'][:,-1:,:,:,:]\n",
    "\n",
    "        batch_counter += 1\n",
    "        yield x,y\n",
    "        if batch_counter == batches:batch_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-10-20T07:04:32.404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f25e50ce61f4943a2ca214239bc2679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data_batches =generate_data_batches(xr,\n",
    "                                          steps=1,\n",
    "                                          max_iters = 100,\n",
    "                                          seed=42,\n",
    "                                          batch_size=32,\n",
    "                                          step_size=10,\n",
    "                                          batches=xr.shape[0]//32,\n",
    "                                          progress=True)\n",
    "#                                           save_file = 'N=100x100 batch_size=64 batches=5000 max_iters=1000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.567761\n"
     ]
    }
   ],
   "source": [
    "## from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow\n",
    "# def dense_block(c0,f,k,s,f1,f2,f3,k1,k2,k3):\n",
    "#     i0 = TimeDistributed(Conv2D(f1,k1,strides=s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(c0)\n",
    "#     i0 = Concatenate()([c0,i0])\n",
    "#     j0 = TimeDistributed(Conv2D(f2,k2,strides=s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(i0)\n",
    "#     j0 =Concatenate()([j0,i0])\n",
    "#     k0 = TimeDistributed(Conv2D(f3,k3,strides=s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(j0)\n",
    "#     k0 =Concatenate()([j0,k0])\n",
    "#     return k0\n",
    "\n",
    "\n",
    "def conv(x,f,k):\n",
    "    x = TimeDistributed(Conv2D(f,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return x\n",
    "    \n",
    "def deconv(x,f,k):\n",
    "    x = TimeDistributed(Conv2DTranspose(f,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return x\n",
    "    \n",
    "    \n",
    "def dense_block(tensor, f, r,k):\n",
    "    for _ in range(r):\n",
    "        x = conv(tensor, f=4*f, k=1)\n",
    "        x = conv(x, f=f, k=k)\n",
    "        tensor = Concatenate()([tensor, x])\n",
    "    return tensor\n",
    "\n",
    "def inv_dense_block(tensor, f, r,k):\n",
    "    for _ in range(r):\n",
    "        x = deconv(tensor, f=4*f, k=1)\n",
    "        x = deconv(x, f=f, k=k)\n",
    "        tensor = Concatenate()([tensor, x])\n",
    "    return tensor\n",
    "\n",
    "def transition(x,s):\n",
    "    ff = int(tensorflow.keras.backend.int_shape(x)[-1] * 0.5)\n",
    "    m0 = TimeDistributed(Conv2D(ff,(1,1),strides=2*s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return m0\n",
    "\n",
    "def inv_transition(x,s):\n",
    "    ff = int(tensorflow.keras.backend.int_shape(x)[-1] * 0.5)\n",
    "    m0 = TimeDistributed(Conv2DTranspose(ff,(1,1),strides=2*s,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "    return m0\n",
    "\n",
    "\n",
    "def dfn():\n",
    "    \n",
    "    k=3#hp.Choice('k',values=[2,3])\n",
    "    \n",
    "    s=1;LR=1e-3\n",
    "    \n",
    "    \n",
    "    r1 = 2#hp.Choice('r1',values=[1,2,3,4,5,6,7,8])\n",
    "    r2 = 4#hp.Choice('r2',values=[1,2,3,4,5,6,7,8])\n",
    "    r3 = 8#hp.Choice('r3',values=[1,2,3,4,5,6,7,8])\n",
    "    \n",
    "    f0 = 128#hp.Choice('f0',values=[4,8,16,32,64,128,256]) \n",
    "    f1 = 32#hp.Choice('fd',values=[4,8,16,32,64])\n",
    "    f2 = 32#hp.Choice('f2',values=[4,8,16,32,64])\n",
    "    f3 = 32#hp.Choice('f3',values=[4,8,16,32,64]) \n",
    "    \n",
    "    l1 = 128#hp.Choice('l1',values=[4,8,12,16,24,32,64,96,128,256])\n",
    "    l2 = 64#hp.Choice('l2',values=[4,8,12,16,24,32,64,96,128,256])\n",
    "    \n",
    "    \n",
    "    x = Input(shape=(None, 12,12, 1))\n",
    "    c0 = TimeDistributed(Conv2D(f0,(k,k),strides=1,padding='same',kernel_initializer='glorot_uniform',activation=LeakyReLU()))(x)\n",
    "########################################################################################################    \n",
    "    e1 = dense_block(c0,f1,r=r1,k=k);m1 = transition(e1,s)\n",
    "    e2 = dense_block(m1,f2,r=r2,k=k);m2 = transition(e2,s)\n",
    "    e3 = dense_block(m2,f3,r=r3,k=k);\n",
    "########################################################################################################\n",
    "    e = ConvLSTM2D(l1,(2,2),padding='same',return_sequences=True)(e3)\n",
    "    b = ConvLSTM2D(l2,(2,2),padding='same',return_sequences=True)(e)\n",
    "    d = ConvLSTM2D(l1,(2,2),padding='same',return_sequences=True)(b)\n",
    "########################################################################################################\n",
    "    d1 = inv_dense_block(d ,f3,r=r3,k=k);m1 = inv_transition(d1,s)\n",
    "    d2 = inv_dense_block(m1,f2,r=r2,k=k);m2 = inv_transition(d2,s)\n",
    "    d3 = inv_dense_block(m2,f1,r=r1,k=k);\n",
    "########################################################################################################\n",
    "    out = conv(d3,f=1,k=1)\n",
    "    model = Model(x,out)\n",
    "    optimizer = Adam(learning_rate=LR)\n",
    "    model.compile(loss='mae',optimizer=optimizer,metrics=['mse'])\n",
    "    \n",
    "    params = model.count_params()/1e6\n",
    "    print(params)\n",
    "#     if params > 4 : return None\n",
    "    return model\n",
    "\n",
    "model = dfn()\n",
    "# model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T06:48:10.103493Z",
     "start_time": "2020-10-15T06:48:10.090529Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "history={}\n",
    "i = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T06:48:30.750229Z",
     "start_time": "2020-10-15T06:48:23.258052Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 294s 74ms/step - loss: 0.0019 - mse: 1.1062e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6538537d30>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### 100 step\n",
    "\n",
    "i+=1\n",
    "\n",
    " \n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    min_delta=5e-5, \n",
    "    patience=25, \n",
    "    verbose=1, \n",
    "    mode='auto',\n",
    "    baseline=None, \n",
    "    restore_best_weights=False\n",
    ")\n",
    "\n",
    "csv_logger = tensorflow.keras.callbacks.CSVLogger('finiteNet - 3 r=1,2,3 f=256,32,32,32.log')\n",
    "reduce_lr_callback = tensorflow.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', \n",
    "                                      factor = 0.5, \n",
    "                                      patience = 3, \n",
    "                                      verbose = 1, \n",
    "                                      cooldown=1,\n",
    "                                      min_delta = 1e-4,\n",
    "                                      min_lr=1e-8 )\n",
    "\n",
    "model.fit(       data_generator(train_data_batches),\n",
    "                    steps_per_epoch=len(train_data_batches),\n",
    "                    verbose=1,\n",
    "                    epochs=1,\n",
    "                    callbacks=[reduce_lr_callback,csv_logger,early_stopping],\n",
    "\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('burger std=0.7968797813840656 mean=1.4804453986909523 loss=0.0019.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7968797813840656, 1.4804453986909523)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std,mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-17T14:59:56.465051Z",
     "start_time": "2020-10-17T14:59:55.611505Z"
    }
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.479030106840812, 0.7964541244780471)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean , std"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}